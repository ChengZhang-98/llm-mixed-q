[default]
name = "block_fp"
bypass = false
is_ptq = true
data_in_width = 6
data_in_exponent_width = 8
data_in_exponent_bias = "NA"
data_in_block_size = [ 1, 16,]
weight_width = 6
weight_exponent_width = 8
weight_exponent_bias = "NA"
weight_block_size = [ 1, 16,]
bias_width = 7
bias_exponent_width = 8
bias_exponent_bias = "NA"
bias_block_size = [ 1, 16,]

[model_layer.fc1]
name = "block_fp"
bypass = false
is_ptq = true
data_in_width = 5
data_in_exponent_width = 8
data_in_exponent_bias = "NA"
data_in_block_size = [ 1, 16,]
weight_width = 6
weight_exponent_width = 8
weight_exponent_bias = "NA"
weight_block_size = [ 1, 16,]
bias_width = 5
bias_exponent_width = 8
bias_exponent_bias = "NA"
bias_block_size = [ 1, 16,]

[model_layer.fc2]
name = "block_fp"
bypass = false
is_ptq = true
data_in_width = 5
data_in_exponent_width = 8
data_in_exponent_bias = "NA"
data_in_block_size = [ 1, 16,]
weight_width = 6
weight_exponent_width = 8
weight_exponent_bias = "NA"
weight_block_size = [ 1, 16,]
bias_width = 6
bias_exponent_width = 8
bias_exponent_bias = "NA"
bias_block_size = [ 1, 16,]

[model_layer.self_attn.q_proj]
name = "block_fp"
bypass = false
is_ptq = true
data_in_width = 6
data_in_exponent_width = 8
data_in_exponent_bias = "NA"
data_in_block_size = [ 1, 16,]
weight_width = 3
weight_exponent_width = 8
weight_exponent_bias = "NA"
weight_block_size = [ 1, 16,]
bias_width = 6
bias_exponent_width = 8
bias_exponent_bias = "NA"
bias_block_size = [ 1, 16,]

[model_layer.self_attn.k_proj]
name = "block_fp"
bypass = false
is_ptq = true
data_in_width = 7
data_in_exponent_width = 8
data_in_exponent_bias = "NA"
data_in_block_size = [ 1, 16,]
weight_width = 3
weight_exponent_width = 8
weight_exponent_bias = "NA"
weight_block_size = [ 1, 16,]
bias_width = 5
bias_exponent_width = 8
bias_exponent_bias = "NA"
bias_block_size = [ 1, 16,]

[model_layer.self_attn.v_proj]
name = "block_fp"
bypass = false
is_ptq = true
data_in_width = 7
data_in_exponent_width = 8
data_in_exponent_bias = "NA"
data_in_block_size = [ 1, 16,]
weight_width = 5
weight_exponent_width = 8
weight_exponent_bias = "NA"
weight_block_size = [ 1, 16,]
bias_width = 5
bias_exponent_width = 8
bias_exponent_bias = "NA"
bias_block_size = [ 1, 16,]

[model_layer.self_attn.out_proj]
name = "block_fp"
bypass = false
is_ptq = true
data_in_width = 5
data_in_exponent_width = 8
data_in_exponent_bias = "NA"
data_in_block_size = [ 1, 16,]
weight_width = 5
weight_exponent_width = 8
weight_exponent_bias = "NA"
weight_block_size = [ 1, 16,]
bias_width = 5
bias_exponent_width = 8
bias_exponent_bias = "NA"
bias_block_size = [ 1, 16,]

[model_layer.self_attn.bmm_0]
name = "block_fp"
bypass = false
is_ptq = true
data_in_width = 5
data_in_exponent_width = 8
data_in_exponent_bias = "NA"
data_in_block_size = [ 1, 16,]
weight_width = 5
weight_exponent_width = 8
weight_exponent_bias = "NA"
weight_block_size = [ 1, 16,]
bias_width = 3
bias_exponent_width = 8
bias_exponent_bias = "NA"
bias_block_size = [ 1, 16,]

[model_layer.self_attn.bmm_1]
name = "block_fp"
bypass = false
is_ptq = true
data_in_width = 7
data_in_exponent_width = 8
data_in_exponent_bias = "NA"
data_in_block_size = [ 1, 16,]
weight_width = 3
weight_exponent_width = 8
weight_exponent_bias = "NA"
weight_block_size = [ 1, 16,]
bias_width = 6
bias_exponent_width = 8
bias_exponent_bias = "NA"
bias_block_size = [ 1, 16,]
