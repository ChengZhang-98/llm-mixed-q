import os
import sys
from pathlib import Path

import torch
from accelerate import init_empty_weights

sys.path.append(str(Path(__file__).parent.parent / "src"))
from llm_mixed_q.models import (
    get_model_cls,
    get_config_cls,
    get_tokenizer_cls,
    get_model_profiler,
)

from llm_mixed_q.models.quantize.quant_config_parser import parse_node_config
from llm_mixed_q.models.opt_quantized.quant_config_opt import (
    create_a_layer_config,
    parse_opt_quantized_config,
)

os.environ["PYTHONBREAKPOINT"] = "ipdb.set_trace"

if __name__ == "__main__":
    config_to_parse = {
        "default": {
            "name": "block_fp",
            "bypass": False,
            "is_ptq": True,
            "data_in_width": 6,
            "data_in_exponent_width": 8,
            "data_in_exponent_bias": None,
            "data_in_block_size": [1, 16],
            "weight_width": 4,
            "weight_exponent_width": 8,
            "weight_exponent_bias": None,
            "weight_block_size": [1, 16],
            "bias_width": 7,
            "bias_exponent_width": 8,
            "bias_exponent_bias": None,
            "bias_block_size": [1, 16],
        },
        "model_layer": {
            "self_attn": {
                "q_proj": {
                    "name": "block_fp",
                    "bypass": False,
                    "is_ptq": True,
                    "data_in_width": 5,
                    "data_in_exponent_width": 8,
                    "data_in_exponent_bias": None,
                    "data_in_block_size": [1, 16],
                    "weight_width": 3,
                    "weight_exponent_width": 8,
                    "weight_exponent_bias": None,
                    "weight_block_size": [1, 16],
                    "bias_width": 5,
                    "bias_exponent_width": 8,
                    "bias_exponent_bias": None,
                    "bias_block_size": [1, 16],
                },
                "k_proj": {
                    "name": "block_fp",
                    "bypass": False,
                    "is_ptq": True,
                    "data_in_width": 4,
                    "data_in_exponent_width": 8,
                    "data_in_exponent_bias": None,
                    "data_in_block_size": [1, 16],
                    "weight_width": 6,
                    "weight_exponent_width": 8,
                    "weight_exponent_bias": None,
                    "weight_block_size": [1, 16],
                    "bias_width": 6,
                    "bias_exponent_width": 8,
                    "bias_exponent_bias": None,
                    "bias_block_size": [1, 16],
                },
                "v_proj": {
                    "name": "block_fp",
                    "bypass": False,
                    "is_ptq": True,
                    "data_in_width": 7,
                    "data_in_exponent_width": 8,
                    "data_in_exponent_bias": None,
                    "data_in_block_size": [1, 16],
                    "weight_width": 6,
                    "weight_exponent_width": 8,
                    "weight_exponent_bias": None,
                    "weight_block_size": [1, 16],
                    "bias_width": 4,
                    "bias_exponent_width": 8,
                    "bias_exponent_bias": None,
                    "bias_block_size": [1, 16],
                },
                "out_proj": {
                    "name": "block_fp",
                    "bypass": False,
                    "is_ptq": True,
                    "data_in_width": 5,
                    "data_in_exponent_width": 8,
                    "data_in_exponent_bias": None,
                    "data_in_block_size": [1, 16],
                    "weight_width": 4,
                    "weight_exponent_width": 8,
                    "weight_exponent_bias": None,
                    "weight_block_size": [1, 16],
                    "bias_width": 5,
                    "bias_exponent_width": 8,
                    "bias_exponent_bias": None,
                    "bias_block_size": [1, 16],
                },
                "bmm_0": {
                    "name": "block_fp",
                    "bypass": False,
                    "is_ptq": True,
                    "data_in_width": 4,
                    "data_in_exponent_width": 8,
                    "data_in_exponent_bias": None,
                    "data_in_block_size": [1, 16],
                    "weight_width": 4,
                    "weight_exponent_width": 8,
                    "weight_exponent_bias": None,
                    "weight_block_size": [1, 16],
                    "bias_width": 4,
                    "bias_exponent_width": 8,
                    "bias_exponent_bias": None,
                    "bias_block_size": [1, 16],
                },
                "bmm_1": {
                    "name": "block_fp",
                    "bypass": False,
                    "is_ptq": True,
                    "data_in_width": 5,
                    "data_in_exponent_width": 8,
                    "data_in_exponent_bias": None,
                    "data_in_block_size": [1, 16],
                    "weight_width": 6,
                    "weight_exponent_width": 8,
                    "weight_exponent_bias": None,
                    "weight_block_size": [1, 16],
                    "bias_width": 4,
                    "bias_exponent_width": 8,
                    "bias_exponent_bias": None,
                    "bias_block_size": [1, 16],
                },
            },
            "fc1": {
                "name": "block_fp",
                "bypass": False,
                "is_ptq": True,
                "data_in_width": 7,
                "data_in_exponent_width": 8,
                "data_in_exponent_bias": None,
                "data_in_block_size": [1, 16],
                "weight_width": 6,
                "weight_exponent_width": 8,
                "weight_exponent_bias": None,
                "weight_block_size": [1, 16],
                "bias_width": 5,
                "bias_exponent_width": 8,
                "bias_exponent_bias": None,
                "bias_block_size": [1, 16],
            },
            "fc2": {
                "name": "block_fp",
                "bypass": False,
                "is_ptq": True,
                "data_in_width": 5,
                "data_in_exponent_width": 8,
                "data_in_exponent_bias": None,
                "data_in_block_size": [1, 16],
                "weight_width": 4,
                "weight_exponent_width": 8,
                "weight_exponent_bias": None,
                "weight_block_size": [1, 16],
                "bias_width": 3,
                "bias_exponent_width": 8,
                "bias_exponent_bias": None,
                "bias_block_size": [1, 16],
            },
        },
    }

    config = parse_opt_quantized_config(config_to_parse, num_hidden_layers=2)
